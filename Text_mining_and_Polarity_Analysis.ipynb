{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Package and Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('reviews_Digital_Music.json.gz')\n",
    "\n",
    "# df.to_csv('reviews_Digital_Music_5.csv', index=True, sep=',')\n",
    "# music_df = pd.read_csv('reviews_Digital_Music_5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The review dataset looks like as the following : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2EFCYXHNK06IS</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Abigail Perkins \"Abby &amp;#34;Reads Too Much&amp;#34...</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>The anthemic title track begins &amp;quot;The Memo...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Enya Experiments And Succeeds</td>\n",
       "      <td>978480000</td>\n",
       "      <td>01 3, 2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1WR23ER5HMAA9</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>AKB</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Just when I thought Enya couldn't possibly get...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>How to improve upon perfection.</td>\n",
       "      <td>953424000</td>\n",
       "      <td>03 19, 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2IR4Q0GPAFJKW</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Alexander</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Nice CD for easy listening.  My husband and I ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good listening.</td>\n",
       "      <td>1393545600</td>\n",
       "      <td>02 28, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2V0KUVAB9HSYO</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Alison Hight</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>I really liked this CD, especially the differe...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Loved It</td>\n",
       "      <td>966124800</td>\n",
       "      <td>08 13, 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1J0GL9HCA7ELW</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Al the Pal \"Al the Pal\"</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>Enya's richly chorded style has smitten me onc...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Another Hauntingly Beautiful Collection of Songs</td>\n",
       "      <td>1007683200</td>\n",
       "      <td>12 7, 2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A2EFCYXHNK06IS  5555991584   \n",
       "1  A1WR23ER5HMAA9  5555991584   \n",
       "2  A2IR4Q0GPAFJKW  5555991584   \n",
       "3  A2V0KUVAB9HSYO  5555991584   \n",
       "4  A1J0GL9HCA7ELW  5555991584   \n",
       "\n",
       "                                       reviewerName helpful  \\\n",
       "0  Abigail Perkins \"Abby &#34;Reads Too Much&#34...  [4, 5]   \n",
       "1                                               AKB  [1, 1]   \n",
       "2                                         Alexander  [0, 0]   \n",
       "3                                      Alison Hight  [0, 1]   \n",
       "4                           Al the Pal \"Al the Pal\"  [3, 3]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  The anthemic title track begins &quot;The Memo...      5.0   \n",
       "1  Just when I thought Enya couldn't possibly get...      5.0   \n",
       "2  Nice CD for easy listening.  My husband and I ...      4.0   \n",
       "3  I really liked this CD, especially the differe...      4.0   \n",
       "4  Enya's richly chorded style has smitten me onc...      5.0   \n",
       "\n",
       "                                            summary  unixReviewTime  \\\n",
       "0                     Enya Experiments And Succeeds       978480000   \n",
       "1                   How to improve upon perfection.       953424000   \n",
       "2                                   Good listening.      1393545600   \n",
       "3                                          Loved It       966124800   \n",
       "4  Another Hauntingly Beautiful Collection of Songs      1007683200   \n",
       "\n",
       "    reviewTime  \n",
       "0   01 3, 2001  \n",
       "1  03 19, 2000  \n",
       "2  02 28, 2014  \n",
       "3  08 13, 2000  \n",
       "4   12 7, 2001  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_filter(text):\n",
    "    text = str(text).lower()\n",
    "    text = ''.join(ch for ch in text if ch not in set(string.punctuation))  # remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)    # remove digits\n",
    "    text = \" \".join(text.split())     # remove white space\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens1 = word_tokenize(text)\n",
    "    text1 = [i for i in tokens1 if not i in stop_words] # remove stop words\n",
    "    text1 = ' '.join(text1) # Back to string\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    tokens2 = word_tokenize(text1)\n",
    "    text2 = [lemmatizer.lemmatize(word) for word in tokens2] # lemmatizer    \n",
    "    return text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_review = list(df['reviewText']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 836006/836006 [26:09<00:00, 532.75it/s]  \n"
     ]
    }
   ],
   "source": [
    "df['reviewText'] = [text_filter(x) for x in tqdm(list_review)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After clean the text feature, it eliminate the redundant parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2EFCYXHNK06IS</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Abigail Perkins \"Abby &amp;#34;Reads Too Much&amp;#34...</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>[anthemic, title, track, begin, quotthe, memor...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Enya Experiments And Succeeds</td>\n",
       "      <td>978480000</td>\n",
       "      <td>01 3, 2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1WR23ER5HMAA9</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>AKB</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[thought, enya, couldnt, possibly, get, better...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>How to improve upon perfection.</td>\n",
       "      <td>953424000</td>\n",
       "      <td>03 19, 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2IR4Q0GPAFJKW</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Alexander</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[nice, cd, easy, listening, husband, like, qui...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good listening.</td>\n",
       "      <td>1393545600</td>\n",
       "      <td>02 28, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2V0KUVAB9HSYO</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Alison Hight</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[really, liked, cd, especially, different, lan...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Loved It</td>\n",
       "      <td>966124800</td>\n",
       "      <td>08 13, 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1J0GL9HCA7ELW</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Al the Pal \"Al the Pal\"</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>[enyas, richly, chorded, style, smitten, littl...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Another Hauntingly Beautiful Collection of Songs</td>\n",
       "      <td>1007683200</td>\n",
       "      <td>12 7, 2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A3EBHHCZO6V2A4</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Amaranth \"music fan\"</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>[hard, believe, memory, tree, came, year, agoi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Enya's last great album</td>\n",
       "      <td>1158019200</td>\n",
       "      <td>09 12, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A340XJYJDFSMUG</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Amazon Customer \"Arlu\"</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>[enya, fan, like, cd, cd, skip, song, song, st...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Something Different</td>\n",
       "      <td>1190419200</td>\n",
       "      <td>09 22, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A3Q1J7VFGG80EK</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Amber</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[im, huge, know, enya, fan, like, music, much,...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Memory of Trees or My favorite Enya CD</td>\n",
       "      <td>975628800</td>\n",
       "      <td>12 1, 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A1REP2FMPOXV4A</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Andrew G.</td>\n",
       "      <td>[6, 8]</td>\n",
       "      <td>[favorite, enya, album, date, even, writing, r...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>In a word, perfection</td>\n",
       "      <td>993427200</td>\n",
       "      <td>06 25, 2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A3QEKUPBPQ7A2S</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Archer</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[love, love, love, love, love, memory, tree, e...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I could listen to this album all day!</td>\n",
       "      <td>1055635200</td>\n",
       "      <td>06 15, 2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A2EFCYXHNK06IS  5555991584   \n",
       "1  A1WR23ER5HMAA9  5555991584   \n",
       "2  A2IR4Q0GPAFJKW  5555991584   \n",
       "3  A2V0KUVAB9HSYO  5555991584   \n",
       "4  A1J0GL9HCA7ELW  5555991584   \n",
       "5  A3EBHHCZO6V2A4  5555991584   \n",
       "6  A340XJYJDFSMUG  5555991584   \n",
       "7  A3Q1J7VFGG80EK  5555991584   \n",
       "8  A1REP2FMPOXV4A  5555991584   \n",
       "9  A3QEKUPBPQ7A2S  5555991584   \n",
       "\n",
       "                                       reviewerName helpful  \\\n",
       "0  Abigail Perkins \"Abby &#34;Reads Too Much&#34...  [4, 5]   \n",
       "1                                               AKB  [1, 1]   \n",
       "2                                         Alexander  [0, 0]   \n",
       "3                                      Alison Hight  [0, 1]   \n",
       "4                           Al the Pal \"Al the Pal\"  [3, 3]   \n",
       "5                              Amaranth \"music fan\"  [3, 3]   \n",
       "6                            Amazon Customer \"Arlu\"  [1, 3]   \n",
       "7                                             Amber  [0, 0]   \n",
       "8                                         Andrew G.  [6, 8]   \n",
       "9                                            Archer  [1, 1]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  [anthemic, title, track, begin, quotthe, memor...      5.0   \n",
       "1  [thought, enya, couldnt, possibly, get, better...      5.0   \n",
       "2  [nice, cd, easy, listening, husband, like, qui...      4.0   \n",
       "3  [really, liked, cd, especially, different, lan...      4.0   \n",
       "4  [enyas, richly, chorded, style, smitten, littl...      5.0   \n",
       "5  [hard, believe, memory, tree, came, year, agoi...      5.0   \n",
       "6  [enya, fan, like, cd, cd, skip, song, song, st...      3.0   \n",
       "7  [im, huge, know, enya, fan, like, music, much,...      5.0   \n",
       "8  [favorite, enya, album, date, even, writing, r...      5.0   \n",
       "9  [love, love, love, love, love, memory, tree, e...      5.0   \n",
       "\n",
       "                                            summary  unixReviewTime  \\\n",
       "0                     Enya Experiments And Succeeds       978480000   \n",
       "1                   How to improve upon perfection.       953424000   \n",
       "2                                   Good listening.      1393545600   \n",
       "3                                          Loved It       966124800   \n",
       "4  Another Hauntingly Beautiful Collection of Songs      1007683200   \n",
       "5                           Enya's last great album      1158019200   \n",
       "6                               Something Different      1190419200   \n",
       "7            Memory of Trees or My favorite Enya CD       975628800   \n",
       "8                             In a word, perfection       993427200   \n",
       "9             I could listen to this album all day!      1055635200   \n",
       "\n",
       "    reviewTime  \n",
       "0   01 3, 2001  \n",
       "1  03 19, 2000  \n",
       "2  02 28, 2014  \n",
       "3  08 13, 2000  \n",
       "4   12 7, 2001  \n",
       "5  09 12, 2006  \n",
       "6  09 22, 2007  \n",
       "7   12 1, 2000  \n",
       "8  06 25, 2001  \n",
       "9  06 15, 2003  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df_clean1.csv\", header = True) ##Export to csv for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 836006/836006 [00:06<00:00, 123409.00it/s]\n"
     ]
    }
   ],
   "source": [
    "list_review1 = list(df_c1['reviewText']) \n",
    "df_c1['reviewText'] = [\" \".join(x) for x in tqdm(list_review1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the cleaned data for word2vec part :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c1.to_csv(\"df_clean2.csv\", header = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID           0\n",
       "asin                 0\n",
       "reviewerName      2420\n",
       "helpful              0\n",
       "reviewText           0\n",
       "overall              0\n",
       "summary              0\n",
       "unixReviewTime       0\n",
       "reviewTime           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    anthemic title track begin quotthe memory tree...\n",
       "1    thought enya couldnt possibly get better found...\n",
       "2    nice cd easy listening husband like quite bit ...\n",
       "3    really liked cd especially different language ...\n",
       "4    enyas richly chorded style smitten little bit ...\n",
       "5    hard believe memory tree came year agoit held ...\n",
       "6    enya fan like cd cd skip song song stick like ...\n",
       "7    im huge know enya fan like music much cd ive h...\n",
       "8    favorite enya album date even writing review c...\n",
       "9    love love love love love memory tree enyaespec...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c1['reviewText'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the word frequency in text review feature, and remove the low frequency (<5) and high frequency (>1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaa</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaa</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaah</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaah</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aac</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aacute</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aacutelbum</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aad</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaf</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aah</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aahs</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaliyah</th>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaliyahs</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aall</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aampm</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aampr</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aand</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aap</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron</th>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aba</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abacab</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aback</th>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abacus</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abaddon</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abair</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aband</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zooming</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zooropa</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoot</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zorba</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zorn</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zorns</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zorro</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zouk</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zowee</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zquot</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zro</th>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zros</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zschech</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ztt</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zu</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zubin</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zucchero</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zug</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zulu</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zum</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuma</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zumba</th>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zumpano</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zune</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zurich</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zutons</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwan</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zydeco</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zz</th>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zztop</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61404 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            frequency\n",
       "aa                215\n",
       "aaa               104\n",
       "aaaa               37\n",
       "aaaaa              24\n",
       "aaaah               8\n",
       "aaah               17\n",
       "aac                21\n",
       "aacute              8\n",
       "aacutelbum         92\n",
       "aad                15\n",
       "aaf                10\n",
       "aah                17\n",
       "aahs               15\n",
       "aaliyah           307\n",
       "aaliyahs           75\n",
       "aall               10\n",
       "aampm              48\n",
       "aampr              21\n",
       "aand               30\n",
       "aap                14\n",
       "aaron            1057\n",
       "ab                280\n",
       "aba                 9\n",
       "abacab             20\n",
       "aback             149\n",
       "abacus             11\n",
       "abaddon            39\n",
       "abair              29\n",
       "aband               8\n",
       "abandon           492\n",
       "...               ...\n",
       "zooming            29\n",
       "zooropa            18\n",
       "zoot               58\n",
       "zorba               9\n",
       "zorn               41\n",
       "zorns              12\n",
       "zorro              17\n",
       "zouk               78\n",
       "zowee              59\n",
       "zquot              11\n",
       "zro               183\n",
       "zros               17\n",
       "zschech            22\n",
       "ztt                20\n",
       "zu                 56\n",
       "zubin              16\n",
       "zucchero           14\n",
       "zug                10\n",
       "zulu               42\n",
       "zum                17\n",
       "zuma                9\n",
       "zumba             589\n",
       "zumpano            15\n",
       "zune              138\n",
       "zurich             13\n",
       "zutons             29\n",
       "zwan               74\n",
       "zydeco            127\n",
       "zz                484\n",
       "zztop              23\n",
       "\n",
       "[61404 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer = CountVectorizer(analyzer='word', stop_words='english', min_df=8, max_df= 1000)\n",
    "Smatrix = word_vectorizer.fit_transform(df_c1['reviewText'])\n",
    "frequencies = sum(Smatrix).toarray()[0]\n",
    "freq_names = word_vectorizer.get_feature_names()\n",
    "freq = pd.DataFrame(frequencies, index = freq_names, columns=['frequency'])\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a proper frequency word bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_freq_word_abs = set(freq_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_review2 = list(df_c1['reviewText']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the low / high frequency word by compare with the word bank created before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delet_extreme_fre(df, proper_freq_word):\n",
    "    for index, each in  enumerate(list_review2):\n",
    "        df_c2['reviewText'][index] = \" \".join(set(each.split()) & proper_freq_word)       \n",
    "    return df_c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "clean2_df = delet_extreme_fre(df_c2, proper_freq_word_abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After cleaned, the text review cleaning part is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2EFCYXHNK06IS</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Abigail Perkins \"Abby &amp;#34;Reads Too Much&amp;#34...</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>clannad flowquot frighteningly quotchina trees...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Enya Experiments And Succeeds</td>\n",
       "      <td>978480000</td>\n",
       "      <td>01 3, 2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1WR23ER5HMAA9</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>AKB</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>enya treesquot conveys enyas</td>\n",
       "      <td>5.0</td>\n",
       "      <td>How to improve upon perfection.</td>\n",
       "      <td>953424000</td>\n",
       "      <td>03 19, 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2IR4Q0GPAFJKW</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Alexander</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good listening.</td>\n",
       "      <td>1393545600</td>\n",
       "      <td>02 28, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2V0KUVAB9HSYO</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Alison Hight</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>particularily enyas</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Loved It</td>\n",
       "      <td>966124800</td>\n",
       "      <td>08 13, 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1J0GL9HCA7ELW</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Al the Pal \"Al the Pal\"</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>massage enya smitten recliner perfectlythis ex...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Another Hauntingly Beautiful Collection of Songs</td>\n",
       "      <td>1007683200</td>\n",
       "      <td>12 7, 2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A2EFCYXHNK06IS  5555991584   \n",
       "1  A1WR23ER5HMAA9  5555991584   \n",
       "2  A2IR4Q0GPAFJKW  5555991584   \n",
       "3  A2V0KUVAB9HSYO  5555991584   \n",
       "4  A1J0GL9HCA7ELW  5555991584   \n",
       "\n",
       "                                       reviewerName helpful  \\\n",
       "0  Abigail Perkins \"Abby &#34;Reads Too Much&#34...  [4, 5]   \n",
       "1                                               AKB  [1, 1]   \n",
       "2                                         Alexander  [0, 0]   \n",
       "3                                      Alison Hight  [0, 1]   \n",
       "4                           Al the Pal \"Al the Pal\"  [3, 3]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  clannad flowquot frighteningly quotchina trees...      5.0   \n",
       "1                       enya treesquot conveys enyas      5.0   \n",
       "2                                                         4.0   \n",
       "3                                particularily enyas      4.0   \n",
       "4  massage enya smitten recliner perfectlythis ex...      5.0   \n",
       "\n",
       "                                            summary  unixReviewTime  \\\n",
       "0                     Enya Experiments And Succeeds       978480000   \n",
       "1                   How to improve upon perfection.       953424000   \n",
       "2                                   Good listening.      1393545600   \n",
       "3                                          Loved It       966124800   \n",
       "4  Another Hauntingly Beautiful Collection of Songs      1007683200   \n",
       "\n",
       "    reviewTime  \n",
       "0   01 3, 2001  \n",
       "1  03 19, 2000  \n",
       "2  02 28, 2014  \n",
       "3  08 13, 2000  \n",
       "4   12 7, 2001  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean2_df = clean2_df[(clean2_df['reviewText'].isna() == False)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polarity Analysis by using Textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each review, we will have a polarity score, and we will consider that score into final score of each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By using this package, each text review will be convert to a positive, negetive or neutral score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "a = clean2_df['reviewText'][0]\n",
    "b = TextBlob(a).sentiment[0]\n",
    "c = TextBlob(a).sentiment[1]\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_score = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polarity Analysis for Reviews\n",
    "X_score['review_polarity'] = clean2_df['reviewText'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "X_score['review_subjectivity'] = clean2_df['reviewText'].apply(lambda x: TextBlob(x).sentiment[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_polarity</th>\n",
       "      <th>review_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_polarity  review_subjectivity\n",
       "0            -0.06                  0.8\n",
       "1             0.00                  0.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_score.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out csv file for using to build a new score for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_score.to_csv(\"Polarity.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
